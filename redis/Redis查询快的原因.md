

### Redis 为什么这么快？

　　很多人只知道是 K/V NoSQl 内存数据库，单线程……这都是没有全面理解 Redis 导致无法继续深问下去。

　　这个问题是基础摸底，我们可以从 Redis 不同**数据类型底层的数据结构实现**、**完全基于内存**、**IO 多路复用网络模型**、**线程模型**、**渐进式 rehash**…...



### Redis到底有多快？

> **官方称：Redis 的 QPS 可以达到约 100000（每秒请求数）**

　　我们可以先说到底有多快，根据官方数据，**Redis 的 QPS 可以达到约 100000（每秒请求数）**，有兴趣的可以参考官方的基准程序测试《How fast is Redis？》，地址：https://redis.io/topics/benchmarks

> **横轴是连接数，纵轴是 QPS。**

　　<img src="..\redis\images\20210709001.png" alt="img" style="zoom:80%;" />



### Redis快从如下几点考虑：

- 1.内存比磁盘快
- 2.单线程模型: Redis网络模型是采用I/O多路复用器，对key的处理是单线程的，避免多线程之间的竞争，
     省去了线程切换带来的时间和空间上的性能开销，也不会导致死锁问题。
- 3.底层数据结构的设计，以及事务的设计和key过期策略，乃至key的查找，还有持久化，都为了快速这个特性而有了自己的特殊实现。
- 4.[Redis利用Pipeline加速查询速度的方法](https://www.cnblogs.com/Terry-Wu/p/12090819.html)



#### 1. 内存

内存直接由 CPU 控制，也就是 CPU 内部集成的内存控制器，所以说内存是直接与 CPU 对接，享受与 CPU 通信的最优带宽。

#### 2.单线程模型

> 我们需要注意的是:千万别说 Redis 就只有一个线程。
>
> Redis 的单线程指的是**Redis 的网络 IO （6x 版本后网络 IO 使用多线程）以及键值对指令读写是由一个线程来执行的。**
>
> 对于 Redis 的持久化、集群数据同步、异步删除等都是其他线程执行。

**单线程指的是 Redis 键值对读写指令的执行是单线程。**

先说官方答案，让人觉得足够严谨，而不是人云亦云去背诵一些博客。

　　**官方答案：因为 Redis 是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽**。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。原文地址：https://redis.io/topics/faq。

##### 1. **为啥不用多线程执行充分利用 CPU 呢？**

　　在运行每个任务之前，CPU 需要知道任务在何处加载并开始运行。也就是说，系统需要帮助它预先设置 CPU 寄存器和程序计数器，这称为 CPU 上下文。

　　**切换上下文时，我们需要完成一系列工作，这是非常消耗资源的操作。**

　　引入多线程开发，就需要使用同步原语来保护共享资源的并发读写，增加代码复杂度和调试难度。

##### 2.单线程有什么好处？

1. 不会因为线程创建导致的性能消耗；
2. 避免上下文切换引起的 CPU 消耗，没有多线程切换的开销；
3. 避免了线程之间的竞争问题，比如添加锁、释放锁、死锁等，不需要考虑各种锁问题。
4. 代码更清晰，处理逻辑简单。



　　I/O 多路复用模型

　　Redis 采用 I/O 多路复用技术，并发处理连接。采用了 epoll + 自己实现的简单的事件框架（Redis事件处理）。

　　epoll 中的读、写、关闭、连接都转化成了事件，然后利用 epoll 的多路复用特性，绝不在 IO 上浪费一点时间。

　　![img](.\images\20210709005.png)

　　Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。



R**edis事件处理:**
		Redis 服务器是典型的事件驱动程序，而事件又分为文件事件(socket 的可读可写事件)与时间事件(定时任务)两大类。已经注册的文件事件存储在event[]数组中， 时间事件形成链表；Redis 底层可以使用4中I/O多路复用模型（kqueue、epoll、select等）根据操作系统的不同选择不同， 关于，多路复用模型相关内容可以查看我的另一篇文章 操作系统IO进化史 所以，epoll本身就效率很高了；但是，随着我们网卡的不断升级，在Redis 6.0之后的版本中，对IO的处理变成了多线程；
为什么**对IO的处理变成了多线程能提高速度？
下面**是Redis6.0之前的情况：

　　<img src=".\images\20210709006.png" alt="img" style="zoom:90%;" />

　　<img src=".\images\20210709007.png" alt="img" style="zoom:90%;" />







#### 3.  Redis高效的数据结构

![img](.\images\20210709003.png)

> 学习 MySQL 的时候我知道为了提高检索速度使用了 B+ Tree 数据结构，所以 Redis 速度快应该也跟数据结构有关。
>
> Redis 一共有 5 种数据类型。
>
> String、List、Hash、Set、SortedSet
>
> 不同的数据类型底层使用了一种或者多种数据结构来支撑，目的就是为了追求更快的速度。

- String

  SDS 简单动态字符串优势

  　　![img](.\images\20210709004.png)

  　　

  1. SDS 中 len 保存这字符串的长度，O(1) 时间复杂度查询字符串长度信息。
  2. 空间预分配：SDS 被修改后，程序不仅会为 SDS 分配所需要的必须空间，还会分配额外的未使用空间。
  3. 惰性空间释放：当对 SDS 进行缩短操作时，程序并不会回收多余的内存空间，而是使用 free 字段将这些字节数量记录下来不释放，后面如果需要 append 操作，则直接使用 free 中未使用的空间，减少了内存的分配。

- zipList 压缩列表

　　压缩列表是 List 、hash、 sorted Set 三种数据类型底层实现之一。

　　当一个列表只有少量数据的时候，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么 Redis 就会使用压缩列表来做列表键的底层实现。

　　![img](..\redis\images\20210709002.png)

　　这样内存紧凑，节约内存。



- quicklist

　　后续版本对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist。

　　**quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。**

　　![img](https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F0622%2F1cac4da7j00qv38v7000ic000jc005xm.jpg&thumbnail=650x2147483647&quality=80&type=jpg)

- skipList 跳跃表

　　sorted set 类型的排序功能便是通过「跳跃列表」数据结构来实现。

　　跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。

　　跳表在链表的基础上，增加了多层级索引，通过索引位置的几个跳转，实现数据的快速定位，如下图所示：

　　![img](https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F0622%2F6824e178j00qv38v7000kc000jf005zm.jpg&thumbnail=650x2147483647&quality=80&type=jpg)

- 整数数组（intset）

　　当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现，节省内存。







#### 4. [Redis利用Pipeline加速查询速度的方法](https://www.cnblogs.com/Terry-Wu/p/12090819.html)

**1. RTT**

Redis 是一种基于客户端-服务端模型以及请求/响应协议的TCP服务。这意味着通常情况下 Redis 客户端执行一条命令分为如下四个过程：

- 发送命令
- 命令排队
- 命令执行
- 返回结果

客户端向服务端发送一个查询请求，并监听Socket返回，通常是以阻塞模式，等待服务端响应。服务端处理命令，并将结果返回给客户端。客户端和服务端通过网络进行连接。这个连接可以很快，也可能很慢。无论网络如何延迟，数据包总是能从客户端到达服务端，服务端返回数据给客户端。

这个时间被称为 RTT (Round Trip Time)，例如上面过程的发送命令和返回结果两个过程。当客户端需要连续执行多次请求时很容易看到这是如何影响性能的（例如，添加多个元素到同一个列表中）。例如，如果 RTT 时间是250毫秒（网络连接很慢的情况下），即使服务端每秒能处理100k的请求量，那我们每秒最多也只能处理4个请求。如果使用的是本地环回接口，RTT 就短得多，但如如果需要连续执行多次写入，这也是一笔很大的开销。

下面我们看一下执行 N 次命令的模型:

<img src=".\images\20197182939410.jpg" alt="img" style="zoom:60%;" />

**2. Pipeline**

我们可以使用 Pipeline 改善这种情况。Pipeline 并不是一种新的技术或机制，很多技术上都使用过。RTT 在不同网络环境下会不同，例如同机房和同机房会比较快，跨机房跨地区会比较慢。Redis 很早就支持 Pipeline 技术，因此无论你运行的是什么版本，你都可以使用 Pipeline 操作 Redis。

Pipeline 能将一组 Redis 命令进行组装，通过一次 RTT 传输给 Redis，再将这组 Redis 命令按照顺序执行并将结果返回给客户端。上图没有使用 Pipeline 执行了 N 条命令，整个过程需要 N 次 RTT。下图为使用 Pipeline 执行 N 条命令，整个过程仅需要 1 次 RTT：

<img src=".\images\20197183008594.jpg" alt="img" style="zoom:60%;" />

Redis 提供了批量操作命令(例如 mget，mset等)，有效的节约了RTT。但大部分命令是不支持批量操作的。

**3. Java Pipeline**

Jedis 也提供了对 Pipeline 特性的支持。我们可以借助 Pipeline 来模拟批量删除，虽然不会像 mget 和 mset 那样是一个原子命令，但是在绝大数情况下可以使用：

**4. 性能测试**

下表给出了不同网络环境下非 Pipeline 和 Pipeline 执行 10000 次 set 操作的效果：

|    网络    |  延迟  | 非Pipeline | Pipeline |
| :--------: | :----: | :--------: | :------: |
|    本机    | 0.17ms |   573ms    |  134ms   |
| 内网服务器 | 0.41ms |   1610ms   |  240ms   |
|  异地机房  |  7ms   |  78499ms   |  1104ms  |

 

 

 

 

 

```
因测试环境不同可能会得到不同的测试数据，本测试 Pipeline 每次携带 100 条命令。
```

我们可以从上表中得出如下结论:

- Pipeline 执行速度一般比逐条执行要快。
- 客户端和服务端的网络延时越大，Pipeline 的效果越明显。

**5. 批量命令与Pipeline对比**

下面我们看一下批量命令与 Pipeline 的区别:

- 原生批量命令是原子的，Pipeline 是非原子的。
- 原生批量命令是一个命令对应多个 key，Pipeline 支持多个命令。
- 原生批量命令是 Redis 服务端支持实现的，而 Pipeline 需要服务端和客户端的共同实现。

**6. 注意点**

使用 Pipeline 发送命令时，每次 Pipeline 组装的命令个数不能没有节制，否则一次组装的命令数据量过大，一方面会增加客户端的等待时间，另一方面会造成一定的网络阻塞，可以将一次包含大量命令的 Pipeline 拆分成多个较小的 Pipeline 来完成。

